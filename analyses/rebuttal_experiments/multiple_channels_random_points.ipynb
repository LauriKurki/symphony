{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import e3nn_jax as e3nn\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import optax\n",
    "import chex\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import functools\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from symphony import loss\n",
    "from symphony import models\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random signal on the sphere, by sampling random points on the sphere.\n",
    "N_points = 5\n",
    "lmax = 5\n",
    "rng = jax.random.PRNGKey(0)\n",
    "random_points = jax.random.normal(rng, (N_points, 3))\n",
    "random_points = random_points / jnp.linalg.norm(random_points, axis=-1, keepdims=True)\n",
    "random_signal = 20 * e3nn.s2_dirac(random_points, lmax=lmax, p_val=1, p_arg=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dist = helpers.average_target_distributions(random_signal, 159, 80)\n",
    "random_dist_copy = e3nn.SphericalSignal(grid_values=random_dist.grid_values[0], quadrature=random_dist.quadrature)\n",
    "fig = go.Figure([go.Surface(random_dist_copy.plotly_surface(scale_radius_by_amplitude=False, radius=0.8, normalize_radius_by_max_amplitude=True)),\n",
    "                 go.Scatter3d(x=random_points[:, 0], y=random_points[:, 1], z=random_points[:, 2], mode='markers')])\n",
    "\n",
    "# Do not show the axis\n",
    "fig.update_layout(scene = dict(\n",
    "                    xaxis = dict(showticklabels=False, visible=False),\n",
    "                    yaxis = dict(showticklabels=False, visible=False),\n",
    "                    zaxis = dict(showticklabels=False, visible=False)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to learn random signal via gradient descent on the KL divergence.\n",
    "def optimize_coeffs(true_signal, lmax, position_channels, res_alpha, res_beta, use_simm_et_al, regularize_coeffs, num_training_steps):\n",
    "\n",
    "    # Compute the target distribution\n",
    "    true_dist = helpers.average_target_distributions(true_signal, res_alpha=res_alpha, res_beta=res_beta)\n",
    "\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    irreps = e3nn.s2_irreps(lmax, p_val=1, p_arg=-1)\n",
    "    coeffs = e3nn.normal(irreps, rng, (position_channels, 1))\n",
    "\n",
    "    tx = optax.adam(1e-3)\n",
    "    opt_state = tx.init(coeffs)\n",
    "\n",
    "    def loss_fn(coeffs):\n",
    "        log_predicted_dist = models.log_coeffs_to_logits(coeffs, res_beta=res_beta, res_alpha=res_alpha, num_radii=1)\n",
    "        if use_simm_et_al:\n",
    "            log_predicted_dist.grid_values = log_predicted_dist.grid_values ** 2\n",
    "            if regularize_coeffs:\n",
    "                log_predicted_dist.grid_values = log_predicted_dist.grid_values / e3nn.norm(coeffs, per_irrep=True, squared=True).array.sum()\n",
    "\n",
    "        return loss.kl_divergence_on_spheres(true_dist, log_predicted_dist)\n",
    "\n",
    "    @jax.jit\n",
    "    def train_step(coeffs, opt_state):\n",
    "        loss_value, grads = jax.value_and_grad(loss_fn)(coeffs)\n",
    "        grad_norms = jnp.linalg.norm(grads.array)\n",
    "        updates, opt_state = tx.update(grads, opt_state, coeffs)\n",
    "        coeffs = optax.apply_updates(coeffs, updates)\n",
    "        return coeffs, opt_state, loss_value, grad_norms\n",
    "\n",
    "\n",
    "    training_dict = {}\n",
    "    for step in range(num_training_steps):\n",
    "        coeffs, opt_state, loss_value, grad_norms = train_step(coeffs, opt_state)\n",
    "        if step % 5000 == 0 or step == num_training_steps - 1:\n",
    "            print(f\"Step {step}, Loss: {loss_value}\")\n",
    "    \n",
    "        if step % 10 == 0:\n",
    "            # step_rng = jax.random.fold_in(rng, step)\n",
    "            # dist = helpers.coeffs_to_distribution(coeffs, res_alpha, res_beta)\n",
    "            # mean_dist, std_dist = helpers.rmse_of_samples(dist, random_points, step_rng, num_samples=1000)\n",
    "            training_dict[step] = {\n",
    "                \"coeffs\": coeffs.array,\n",
    "                \"loss_value\": float(loss_value.item()),\n",
    "                \"grad_norms\": float(grad_norms.item()),\n",
    "                # \"mean_dist\": float(mean_dist),\n",
    "                # \"std_dist\": float(std_dist),\n",
    "            }\n",
    "\n",
    "    return training_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We vary the number of position channels and lmax.\n",
    "# See how well we can learn the signal.\n",
    "results_df = pd.DataFrame(columns=[\"res_alpha\", \"res_beta\", \"lmax\", \"position_channels\", \"loss\", \"loss_diff\", \"coeffs\", \"grad_norms\", \"use_simm_et_al\", \"regularize_coeffs\"])\n",
    "for res_alpha in [179]:\n",
    "    for res_beta in [90]:\n",
    "        for lmax in range(1, 6):\n",
    "            for position_channels in range(1, 10):\n",
    "                for use_simm_et_al in [True, False]:\n",
    "                    for regularize_coeffs in [True, False]:\n",
    "                        if regularize_coeffs and not use_simm_et_al:\n",
    "                            continue\n",
    "\n",
    "                        training_dict = optimize_coeffs(random_signal, lmax, position_channels, res_alpha, res_beta, use_simm_et_al, regularize_coeffs, num_training_steps=10000) \n",
    "                \n",
    "                        first_step = list(training_dict.keys())[0]\n",
    "                        last_step = list(training_dict.keys())[-1]\n",
    "                        second_last_step = list(training_dict.keys())[-2]\n",
    "                        loss_diff = (training_dict[last_step][\"loss_value\"] - training_dict[second_last_step][\"loss_value\"]) / (second_last_step - last_step)\n",
    "                        assert first_step == 0\n",
    "                        \n",
    "                        results_df = results_df.append({\n",
    "                            \"res_alpha\": res_alpha,\n",
    "                            \"res_beta\": res_beta,\n",
    "                            \"lmax\": lmax,\n",
    "                            \"position_channels\": position_channels,\n",
    "                            \"loss\": training_dict[last_step][\"loss_value\"],\n",
    "                            \"loss_diff\": loss_diff,\n",
    "                            \"grad_norms\": training_dict[last_step][\"grad_norms\"],\n",
    "                            \"coeffs\": training_dict[last_step][\"coeffs\"],\n",
    "                            \"use_simm_et_al\": use_simm_et_al,\n",
    "                            \"regularize_coeffs\": regularize_coeffs,\n",
    "                        }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(5, 5), sharey=True, sharex=True)\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Make 1 plot, one for results where:\n",
    "# * use_simm_et_al = True, regularize_coeffs = True\n",
    "# * use_simm_et_al = True, regularize_coeffs = False\n",
    "sns.barplot(data=results_df[results_df[\"use_simm_et_al\"] == False], x=\"lmax\", y=\"loss\", hue=\"position_channels\", palette=\"Blues\", ax=ax)\n",
    "\n",
    "\n",
    "fig.suptitle(\"KL Divergence on Random Signal\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylim([1e-4, 1e1])\n",
    "\n",
    "# Remove legends\n",
    "ax.get_legend().remove()\n",
    "\n",
    "# Set x-axis label as \"Max L\"\n",
    "ax.set_xlabel(\"Max L\")\n",
    "# ax.set_title(\"Symphony Parametrization\")\n",
    "\n",
    "# Set y-axis label as \"KL Divergence\"\n",
    "ax.set_ylabel(\"KL Divergence\")\n",
    "# Place legend outside the figure\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.5), loc=\"center left\", borderaxespad=0., title=\"Position Channels\")\n",
    "plt.savefig(\"pdfs/kl_divergence_random_signal.pdf\", dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5), sharey=True, sharex=True)\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "# Make 2 plots, one for results where:\n",
    "# * use_simm_et_al = True, regularize_coeffs = True\n",
    "# * use_simm_et_al = True, regularize_coeffs = False\n",
    "sns.barplot(data=results_df[(results_df[\"use_simm_et_al\"] == True) & (results_df[\"regularize_coeffs\"] == True)], x=\"lmax\", y=\"loss\", hue=\"position_channels\", palette=\"Blues\", ax=axs[0])\n",
    "sns.barplot(data=results_df[(results_df[\"use_simm_et_al\"] == True) & (results_df[\"regularize_coeffs\"] == False)], x=\"lmax\", y=\"loss\", hue=\"position_channels\", palette=\"Blues\", ax=axs[1])\n",
    "\n",
    "\n",
    "fig.suptitle(\"KL Divergence on Random Signal\")\n",
    "# Remove legends\n",
    "axs[0].get_legend().remove()\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[0].set_ylim([1e-4, 1e1])\n",
    "\n",
    "# Set x-axis label as \"Max L\"\n",
    "axs[0].set_xlabel(\"Max L\")\n",
    "axs[1].set_xlabel(\"Max L\")\n",
    "axs[0].set_title(\"Simm et al. (2021) Parametrization\")\n",
    "axs[1].set_title(\"Simm et al. (2021) Parametrization without Regularization\")\n",
    "\n",
    "# Set y-axis label as \"KL Divergence\"\n",
    "axs[0].set_ylabel(\"KL Divergence\")\n",
    "axs[1].set_ylabel(\"KL Divergence\")\n",
    "\n",
    "# Place legend outside the figure\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.5), loc=\"center left\", borderaxespad=0., title=\"Position Channels\")\n",
    "plt.savefig(\"pdfs/kl_divergence_random_signal_simm.pdf\", dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 5\n",
    "position_channels = 1\n",
    "use_simm_et_al = True\n",
    "regularize_coeffs = True\n",
    "\n",
    "results_df_subset = results_df[(results_df[\"lmax\"] == lmax) & (results_df[\"use_simm_et_al\"] == use_simm_et_al) & (results_df[\"regularize_coeffs\"] == regularize_coeffs) & (results_df[\"position_channels\"] == position_channels)]\n",
    "print(results_df_subset)\n",
    "\n",
    "coeffs = results_df_subset[\"coeffs\"].values.item()\n",
    "coeffs = e3nn.IrrepsArray(e3nn.s2_irreps(lmax, p_val=1, p_arg=-1), coeffs)\n",
    "\n",
    "predicted_dist = models.log_coeffs_to_logits(coeffs, res_beta=90, res_alpha=179, num_radii=1)\n",
    "if use_simm_et_al:\n",
    "    predicted_dist.grid_values = predicted_dist.grid_values ** 2\n",
    "    if regularize_coeffs:\n",
    "        predicted_dist.grid_values = predicted_dist.grid_values / e3nn.norm(coeffs, per_irrep=True, squared=True).array.sum()\n",
    "\n",
    "predicted_dist = models.position_logits_to_position_distribution(predicted_dist)\n",
    "samples_rng, rng = jax.random.split(rng)\n",
    "samples = helpers.sample_from_dist(predicted_dist, samples_rng, num_samples=10)\n",
    "\n",
    "predicted_dist.grid_values = predicted_dist.grid_values[0]\n",
    "fig = go.Figure([go.Surface(predicted_dist.plotly_surface(scale_radius_by_amplitude=False, radius=0.8, normalize_radius_by_max_amplitude=True)),\n",
    "                 go.Scatter3d(x=samples[:, 0], y=samples[:, 1], z=samples[:, 2], mode='markers'),\n",
    "                 go.Scatter3d(x=random_points[:, 0], y=random_points[:, 1], z=random_points[:, 2], mode='markers')])\n",
    "fig.update_layout(scene = dict(\n",
    "                    xaxis = dict(showticklabels=False, visible=False),\n",
    "                    yaxis = dict(showticklabels=False, visible=False),\n",
    "                    zaxis = dict(showticklabels=False, visible=False)))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
