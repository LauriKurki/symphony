{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import e3nn_jax as e3nn\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import optax\n",
    "import chex\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import functools\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from symphony import loss\n",
    "from symphony import models\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_alphas = [9, 179, 359, 719]\n",
    "res_betas = [10, 180, 360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random signal on the sphere, by sampling random points on the sphere.\n",
    "N_points = 5\n",
    "lmax = 5\n",
    "rng = jax.random.PRNGKey(0)\n",
    "random_points = jax.random.normal(rng, (N_points, 3))\n",
    "random_points = random_points / jnp.linalg.norm(random_points, axis=-1, keepdims=True)\n",
    "random_signal = 20 * e3nn.s2_dirac(random_points, lmax=lmax, p_val=1, p_arg=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dist = helpers.average_target_distributions(random_signal, 159, 80)\n",
    "best_mean_dist, best_std_dist = helpers.rmse_of_samples(random_dist, random_points, rng)\n",
    "print(best_mean_dist, best_std_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dist_copy = e3nn.SphericalSignal(grid_values=random_dist.grid_values[0], quadrature=random_dist.quadrature)\n",
    "fig = go.Figure([go.Surface(random_dist_copy.plotly_surface(scale_radius_by_amplitude=False, radius=0.8, normalize_radius_by_max_amplitude=True)),\n",
    "                 go.Scatter3d(x=random_points[:, 0], y=random_points[:, 1], z=random_points[:, 2], mode='markers')])\n",
    "\n",
    "# Do not show the axis\n",
    "fig.update_layout(scene = dict(\n",
    "                    xaxis = dict(showticklabels=False, visible=False),\n",
    "                    yaxis = dict(showticklabels=False, visible=False),\n",
    "                    zaxis = dict(showticklabels=False, visible=False)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to learn random signal via gradient descent on the KL divergence.\n",
    "def optimize_coeffs(true_signal, lmax, position_channels, res_alpha, res_beta, num_training_steps):\n",
    "\n",
    "    # Compute the target distribution\n",
    "    true_dist = helpers.average_target_distributions(true_signal, res_alpha, res_beta)\n",
    "\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    irreps = e3nn.s2_irreps(lmax, p_val=1, p_arg=-1)\n",
    "    coeffs = e3nn.normal(irreps, rng, (position_channels, 1))\n",
    "\n",
    "    tx = optax.adam(1e-3)\n",
    "    opt_state = tx.init(coeffs)\n",
    "\n",
    "    def loss_fn(coeffs):\n",
    "        log_predicted_dist = models.log_coeffs_to_logits(coeffs, res_beta=res_beta, res_alpha=res_alpha, num_radii=1)\n",
    "        return loss.kl_divergence_on_spheres(true_dist, log_predicted_dist)\n",
    "\n",
    "    @jax.jit\n",
    "    def train_step(coeffs, opt_state):\n",
    "        loss_value, grads = jax.value_and_grad(loss_fn)(coeffs)\n",
    "        grad_norms = jnp.linalg.norm(grads.array)\n",
    "        updates, opt_state = tx.update(grads, opt_state, coeffs)\n",
    "        coeffs = optax.apply_updates(coeffs, updates)\n",
    "        return coeffs, opt_state, loss_value, grad_norms\n",
    "\n",
    "\n",
    "    training_dict = {}\n",
    "    for step in range(num_training_steps):\n",
    "        coeffs, opt_state, loss_value, grad_norms = train_step(coeffs, opt_state)\n",
    "        if step % 5000 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss_value}\")\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            step_rng = jax.random.fold_in(rng, step)\n",
    "            dist = helpers.coeffs_to_distribution(coeffs, res_alpha, res_beta)\n",
    "            mean_dist, std_dist = helpers.rmse_of_samples(dist, random_points, step_rng, num_samples=1000)\n",
    "            \n",
    "            training_dict[step] = {\n",
    "                \"coeffs\": coeffs.array,\n",
    "                \"loss_value\": float(loss_value),\n",
    "                \"grad_norms\": float(grad_norms),\n",
    "                \"mean_dist\": float(mean_dist),\n",
    "                \"std_dist\": float(std_dist),\n",
    "            }\n",
    "\n",
    "    return training_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We vary the number of position channels and lmax.\n",
    "# See how well we can learn the signal.\n",
    "results_df = pd.DataFrame(columns=[\"res_alpha\", \"res_beta\", \"lmax\", \"position_channels\", \"loss\", \"coeffs\", \"grad_norms\", \"mean_dist\", \"std_dist\"])\n",
    "for res_alpha in res_alphas:\n",
    "    for res_beta in res_betas:\n",
    "        for lmax in [5]:\n",
    "            for position_channels in [2]:\n",
    "                training_dict = optimize_coeffs(random_signal, lmax, position_channels, res_alpha, res_beta, num_training_steps=10000) \n",
    "                \n",
    "                first_step = list(training_dict.keys())[0]\n",
    "                last_step = list(training_dict.keys())[-1]\n",
    "                assert first_step == 0\n",
    "\n",
    "                results_df = results_df.append({\n",
    "                    \"res_alpha\": res_alpha,\n",
    "                    \"res_beta\": res_beta,\n",
    "                    \"lmax\": lmax,\n",
    "                    \"position_channels\": position_channels,\n",
    "                    \"steps\": [step for step in training_dict.keys()],\n",
    "                    \"loss\": [training_dict[step][\"loss_value\"] for step in training_dict.keys()],\n",
    "                    \"grad_norms\": [training_dict[step][\"grad_norms\"] for step in training_dict.keys()],\n",
    "                    \"coeffs\": training_dict[last_step][\"coeffs\"],\n",
    "                    \"mean_dist\": [training_dict[step][\"mean_dist\"] for step in training_dict.keys()],\n",
    "                    \"std_dist\": [training_dict[step][\"std_dist\"] for step in training_dict.keys()],\n",
    "                }, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_value(res_alpha, res_beta):\n",
    "    return np.cbrt((res_alpha * res_beta) / (np.max(res_alphas) * np.max(res_betas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a line plot of loss vs. number of training steps, for each choice of res_alpha and res_beta.\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12, 5))\n",
    "sns.set_style(\"darkgrid\")\n",
    "for res_alpha in res_alphas:\n",
    "    for res_beta in res_betas:\n",
    "        allowed_res_alphas_and_betas = [(9, 10), (9, 180), (179, 180), (359, 180), (719, 360)]\n",
    "        if (res_alpha, res_beta) not in allowed_res_alphas_and_betas:\n",
    "            continue\n",
    "        color_value = get_color_value(res_alpha, res_beta)\n",
    "        color = plt.cm.viridis(color_value)\n",
    "        subset_df = results_df[(results_df[\"res_alpha\"] == res_alpha) & (results_df[\"res_beta\"] == res_beta)]\n",
    "        steps = subset_df[\"steps\"].iloc[0]\n",
    "        loss = jnp.asarray(subset_df[\"loss\"].iloc[0])\n",
    "        grad_norms = jnp.asarray(subset_df[\"grad_norms\"].iloc[0])\n",
    "        mean_dist = jnp.asarray(subset_df[\"mean_dist\"].iloc[0])\n",
    "\n",
    "        axs[0].plot(steps, loss,\n",
    "                    label=fr\"$(r_\\theta, r_\\phi) = ({res_beta},{res_alpha})$\",\n",
    "                    color=color)\n",
    "\n",
    "        axs[1].plot(steps, grad_norms,\n",
    "                    label=fr\"$(r_\\theta, r_\\phi) = ({res_beta},{res_alpha})$\",\n",
    "                    color=color)\n",
    "\n",
    "        axs[2].plot(steps, mean_dist,\n",
    "                label=fr\"$(r_\\theta, r_\\phi) = ({res_beta},{res_alpha})$\",\n",
    "                color=color)\n",
    "    \n",
    "        # Also plot the std of the rmse, to get a sense of the variance.\n",
    "        # std_dist = jnp.asarray(subset_df[\"std_dist\"].iloc[0])\n",
    "        # ax.fill_between(steps, mean_dist - std_dist, mean_dist + std_dist, alpha=0.2, color=color)\n",
    "\n",
    "\n",
    "def extract_resolution_from_label(args):\n",
    "    label, handle = args\n",
    "    label = label.replace(\"$\", \"\")\n",
    "    label = label.replace(\"(\", \"\")\n",
    "    label = label.replace(\")\", \"\")\n",
    "    label = label.split(\"=\")[1].split(\",\")\n",
    "    res_alpha = int(label[0])\n",
    "    res_beta = int(label[1])\n",
    "    return res_alpha * res_beta\n",
    "\n",
    "fig.suptitle(\"Learning a Random Distribution on the Sphere\", fontsize=16)\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[0].set_title(\"KL Divergence Loss\")\n",
    "axs[0].set_ylabel(\"KL Divergence Loss\")\n",
    "axs[0].set_xlabel(\"Number of Training Steps\")\n",
    "\n",
    "axs[1].set_yscale(\"log\")\n",
    "axs[1].set_title(\"Gradient Norms\")\n",
    "axs[1].set_ylabel(\"Gradient Norms\")\n",
    "axs[1].set_xlabel(\"Number of Training Steps\")\n",
    "\n",
    "axs[2].set_title(\"Mean Distance to Closest Target Point\")\n",
    "axs[2].set_ylabel(\"Mean Distance to Closest Target Point\")\n",
    "axs[2].set_xlabel(\"Number of Training Steps\")\n",
    "\n",
    "# Sort legend by resolution\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "labels, handles = zip(*sorted(zip(labels, handles), key=extract_resolution_from_label))\n",
    "plt.legend(handles, labels, bbox_to_anchor=(1.05, 0.5), loc=\"center left\", borderaxespad=0., title=r\"Resolution ($r_\\theta, r_\\phi$)\")\n",
    "plt.savefig(\"pdfs/resolution_random_points.pdf\", dpi=500, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 5\n",
    "position_channels = 1\n",
    "\n",
    "coeffs = results_df[results_df[\"lmax\"] == lmax][\"coeffs\"].values[position_channels - 1]\n",
    "coeffs = e3nn.IrrepsArray(e3nn.s2_irreps(lmax, p_val=1, p_arg=-1), coeffs)\n",
    "predicted_dist = models.log_coeffs_to_logits(coeffs, res_beta=90, res_alpha=179, num_radii=1)\n",
    "predicted_dist = models.position_logits_to_position_distribution(predicted_dist)\n",
    "samples_rng, rng = jax.random.split(rng)\n",
    "samples = helpers.sample_from_dist(predicted_dist, samples_rng, num_samples=1000)\n",
    "\n",
    "predicted_dist.grid_values = predicted_dist.grid_values[0]\n",
    "fig = go.Figure([go.Surface(predicted_dist.plotly_surface(scale_radius_by_amplitude=False, radius=0.8, normalize_radius_by_max_amplitude=True)),\n",
    "                 go.Scatter3d(x=samples[:, 0], y=samples[:, 1], z=samples[:, 2], mode='markers'),\n",
    "                 go.Scatter3d(x=random_points[:, 0], y=random_points[:, 1], z=random_points[:, 2], mode='markers')])\n",
    "fig.update_layout(scene = dict(\n",
    "                    xaxis = dict(showticklabels=False, visible=False),\n",
    "                    yaxis = dict(showticklabels=False, visible=False),\n",
    "                    zaxis = dict(showticklabels=False, visible=False)))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
